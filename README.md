# FastChat
| [**æ¼”ç¤º**](https://chat.lmsys.org/) | [**Discord**](https://discord.gg/HSWAKCrnFx) | [**X**](https://x.com/lmsysorg) |

FastChat æ˜¯ä¸€ä¸ªç”¨äºè®­ç»ƒã€éƒ¨ç½²å’Œè¯„ä¼°åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„èŠå¤©æœºå™¨äººçš„å¼€æ”¾å¹³å°ã€‚
- FastChat ä¸º Chatbot Arena (https://chat.lmsys.org/) æä¾›æ”¯æŒï¼Œä¸º70å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹æä¾›äº†è¶…è¿‡1000ä¸‡æ¬¡çš„èŠå¤©è¯·æ±‚æœåŠ¡ã€‚
- Chatbot Arena å·²æ”¶é›†äº†è¶…è¿‡50ä¸‡æ¬¡äººå·¥æŠ•ç¥¨ï¼Œè¿™äº›æŠ•ç¥¨æ¥è‡ªå¤§è¯­è¨€æ¨¡å‹çš„ä¸€å¯¹ä¸€å¯¹æˆ˜ï¼Œç”¨äºç¼–åˆ¶åœ¨çº¿[LLM Elo æ’è¡Œæ¦œ](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)ã€‚

FastChat çš„æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼š
- æœ€å…ˆè¿›æ¨¡å‹ï¼ˆå¦‚ Vicunaã€MT-Benchï¼‰çš„è®­ç»ƒå’Œè¯„ä¼°ä»£ç ã€‚
- å…·æœ‰ç½‘é¡µç•Œé¢å’Œå…¼å®¹ OpenAI çš„ RESTful API çš„åˆ†å¸ƒå¼å¤šæ¨¡å‹æœåŠ¡ç³»ç»Ÿã€‚

## æ–°é—»
- [2024/03] ğŸ”¥ æˆ‘ä»¬å‘å¸ƒäº† Chatbot Arena æŠ€æœ¯[æŠ¥å‘Š](https://arxiv.org/abs/2403.04132)ã€‚
- [2023/09] æˆ‘ä»¬å‘å¸ƒäº† **LMSYS-Chat-1M**ï¼Œä¸€ä¸ªå¤§è§„æ¨¡çœŸå®ä¸–ç•Œ LLM å¯¹è¯æ•°æ®é›†ã€‚é˜…è¯»[æŠ¥å‘Š](https://arxiv.org/abs/2309.11998)ã€‚
- [2023/08] æˆ‘ä»¬å‘å¸ƒäº†åŸºäº Llama 2 çš„ **Vicuna v1.5**ï¼Œå…·æœ‰ 4K å’Œ 16K ä¸Šä¸‹æ–‡é•¿åº¦ã€‚ä¸‹è½½[æƒé‡](#vicuna-weights)ã€‚
- [2023/07] æˆ‘ä»¬å‘å¸ƒäº† **Chatbot Arena Conversations**ï¼Œä¸€ä¸ªåŒ…å« 33k å¯¹è¯åŠäººç±»åå¥½çš„æ•°æ®é›†ã€‚åœ¨[è¿™é‡Œ](https://huggingface.co/datasets/lmsys/chatbot_arena_conversations)ä¸‹è½½ã€‚

<details>
<summary>æ›´å¤š</summary>

- [2023/08] æˆ‘ä»¬å‘å¸ƒäº†åŸºäº Llama 2 çš„ **LongChat v1.5**ï¼Œå…·æœ‰ 32K ä¸Šä¸‹æ–‡é•¿åº¦ã€‚ä¸‹è½½[æƒé‡](#longchat)ã€‚
- [2023/06] æˆ‘ä»¬æ¨å‡ºäº† **MT-bench**ï¼Œä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„å¤šè½®é—®é¢˜é›†ï¼Œç”¨äºè¯„ä¼°èŠå¤©æœºå™¨äººã€‚æŸ¥çœ‹åšå®¢[æ–‡ç« ](https://lmsys.org/blog/2023-06-22-leaderboard/)ã€‚
- [2023/06] æˆ‘ä»¬æ¨å‡ºäº† **LongChat**ï¼Œæˆ‘ä»¬çš„é•¿ä¸Šä¸‹æ–‡èŠå¤©æœºå™¨äººå’Œè¯„ä¼°å·¥å…·ã€‚æŸ¥çœ‹åšå®¢[æ–‡ç« ](https://lmsys.org/blog/2023-06-29-longchat/)ã€‚
- [2023/05] æˆ‘ä»¬æ¨å‡ºäº† **Chatbot Arena**ï¼Œç”¨äº LLM ä¹‹é—´çš„å¯¹æˆ˜ã€‚æŸ¥çœ‹åšå®¢[æ–‡ç« ](https://lmsys.org/blog/2023-05-03-arena)ã€‚
- [2023/03] æˆ‘ä»¬å‘å¸ƒäº† **Vicunaï¼šä¸€ä¸ªå¼€æºèŠå¤©æœºå™¨äººï¼Œä»¥ 90% ChatGPT çš„è´¨é‡ä»¤ GPT-4 å°è±¡æ·±åˆ»**ã€‚æŸ¥çœ‹åšå®¢[æ–‡ç« ](https://vicuna.lmsys.org)ã€‚

</details>

<a href="https://chat.lmsys.org"><img src="assets/demo_narrow.gif" width="70%"></a>

## ç›®å½•
- [å®‰è£…](#install)
- [æ¨¡å‹æƒé‡](#model-weights)
- [å‘½ä»¤è¡Œç•Œé¢æ¨ç†](#inference-with-command-line-interface)
- [Web GUI æœåŠ¡](#serving-with-web-gui)
- [API](#api)
- [è¯„ä¼°](#evaluation)
- [å¾®è°ƒ](#fine-tuning)
- [å¼•ç”¨](#citation)

## å®‰è£…

### æ–¹æ³• 1ï¼šä½¿ç”¨ pip

```bash
pip3 install "fschat[model_worker,webui]"
```

### æ–¹æ³• 2ï¼šä»æºç å®‰è£…

1. å…‹éš†æ­¤ä»“åº“å¹¶è¿›å…¥ FastChat æ–‡ä»¶å¤¹
```bash
git clone https://github.com/lm-sys/FastChat.git
cd FastChat
```

å¦‚æœä½ åœ¨ Mac ä¸Šè¿è¡Œï¼š
```bash
brew install rust cmake
```

2. å®‰è£…åŒ…
```bash
pip3 install --upgrade pip  # å¯ç”¨ PEP 660 æ”¯æŒ
pip3 install -e ".[model_worker,webui]"
```

## æ¨¡å‹æƒé‡
### Vicuna æƒé‡
[Vicuna](https://lmsys.org/blog/2023-03-30-vicuna/) åŸºäº Llama 2ï¼Œåº”åœ¨ Llama çš„[æ¨¡å‹è®¸å¯](https://github.com/facebookresearch/llama/blob/main/LICENSE)ä¸‹ä½¿ç”¨ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¼€å§‹èŠå¤©ã€‚å®ƒä¼šè‡ªåŠ¨ä» Hugging Face ä»“åº“ä¸‹è½½æƒé‡ã€‚
ä¸‹è½½çš„æƒé‡å­˜å‚¨åœ¨ç”¨æˆ·ä¸»æ–‡ä»¶å¤¹çš„ `.cache` æ–‡ä»¶å¤¹ä¸­ï¼ˆä¾‹å¦‚ï¼Œ`~/.cache/huggingface/hub/<model_name>`ï¼‰ã€‚

åœ¨ä¸‹é¢çš„"å‘½ä»¤è¡Œç•Œé¢æ¨ç†"éƒ¨åˆ†æŸ¥çœ‹æ›´å¤šå‘½ä»¤é€‰é¡¹å’Œå¦‚ä½•å¤„ç†å†…å­˜ä¸è¶³çš„æƒ…å†µã€‚

**æ³¨æ„ï¼š16K ç‰ˆæœ¬éœ€è¦ `transformers>=4.31`ã€‚**

| å¤§å° | èŠå¤©å‘½ä»¤ | Hugging Face ä»“åº“ |
| ---  | --- | --- |
| 7B   | `python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5`  | [lmsys/vicuna-7b-v1.5](https://huggingface.co/lmsys/vicuna-7b-v1.5)   |
| 7B-16k   | `python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5-16k`  | [lmsys/vicuna-7b-v1.5-16k](https://huggingface.co/lmsys/vicuna-7b-v1.5-16k)   |
| 13B  | `python3 -m fastchat.serve.cli --model-path lmsys/vicuna-13b-v1.5` | [lmsys/vicuna-13b-v1.5](https://huggingface.co/lmsys/vicuna-13b-v1.5) |
| 13B-16k  | `python3 -m fastchat.serve.cli --model-path lmsys/vicuna-13b-v1.5-16k` | [lmsys/vicuna-13b-v1.5-16k](https://huggingface.co/lmsys/vicuna-13b-v1.5-16k) |
| 33B  | `python3 -m fastchat.serve.cli --model-path lmsys/vicuna-33b-v1.3` | [lmsys/vicuna-33b-v1.3](https://huggingface.co/lmsys/vicuna-33b-v1.3) |

**æ—§æƒé‡**ï¼šæŸ¥çœ‹ [docs/vicuna_weights_version.md](docs/vicuna_weights_version.md) äº†è§£æ‰€æœ‰ç‰ˆæœ¬çš„æƒé‡åŠå…¶å·®å¼‚ã€‚

### å…¶ä»–æ¨¡å‹
é™¤äº† Vicunaï¼Œæˆ‘ä»¬è¿˜å‘å¸ƒäº†ä¸¤ä¸ªé¢å¤–çš„æ¨¡å‹ï¼š[LongChat](https://lmsys.org/blog/2023-06-29-longchat/) å’Œ FastChat-T5ã€‚
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸å®ƒä»¬èŠå¤©ã€‚å®ƒä»¬ä¼šè‡ªåŠ¨ä» Hugging Face ä»“åº“ä¸‹è½½æƒé‡ã€‚

| æ¨¡å‹ | èŠå¤©å‘½ä»¤ | Hugging Face ä»“åº“ |
| ---  | --- | --- |
| LongChat-7B   | `python3 -m fastchat.serve.cli --model-path lmsys/longchat-7b-32k-v1.5`  | [lmsys/longchat-7b-32k](https://huggingface.co/lmsys/longchat-7b-32k-v1.5)   |
| FastChat-T5-3B   | `python3 -m fastchat.serve.cli --model-path lmsys/fastchat-t5-3b-v1.0`  | [lmsys/fastchat-t5-3b-v1.0](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0) |

## å‘½ä»¤è¡Œç•Œé¢æ¨ç†

<a href="https://chat.lmsys.org"><img src="assets/screenshot_cli.png" width="70%"></a>

ï¼ˆå®éªŒæ€§åŠŸèƒ½ï¼šä½ å¯ä»¥æŒ‡å®š `--style rich` æ¥å¯ç”¨å¯Œæ–‡æœ¬è¾“å‡ºå’Œæ›´å¥½çš„é ASCII å†…å®¹çš„æ–‡æœ¬æµè´¨é‡ã€‚è¿™å¯èƒ½åœ¨æŸäº›ç»ˆç«¯ä¸Šæ— æ³•æ­£å¸¸å·¥ä½œã€‚ï¼‰

#### æ”¯æŒçš„æ¨¡å‹
FastChat æ”¯æŒå¹¿æ³›çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬
LLama 2ã€Vicunaã€Alpacaã€Baizeã€ChatGLMã€Dollyã€Falconã€FastChat-T5ã€GPT4ALLã€Guanacoã€MTPã€OpenAssistantã€OpenChatã€RedPajamaã€StableLMã€WizardLMã€xDAN-AI ç­‰ã€‚

æŸ¥çœ‹[è¿™é‡Œ](docs/model_support.md)äº†è§£æ”¯æŒçš„æ¨¡å‹å®Œæ•´åˆ—è¡¨å’Œæ·»åŠ æ–°æ¨¡å‹çš„è¯´æ˜ã€‚

#### å• GPU
ä»¥ä¸‹å‘½ä»¤éœ€è¦çº¦ 14GB GPU å†…å­˜ç”¨äº Vicuna-7Bï¼Œ28GB GPU å†…å­˜ç”¨äº Vicuna-13Bã€‚
å¦‚æœä½ æ²¡æœ‰è¶³å¤Ÿçš„å†…å­˜ï¼Œè¯·å‚è§ä¸‹é¢çš„["å†…å­˜ä¸è¶³"éƒ¨åˆ†](#not-enough-memory)ã€‚
`--model-path` å¯ä»¥æ˜¯æœ¬åœ°æ–‡ä»¶å¤¹æˆ– Hugging Face ä»“åº“åç§°ã€‚
```
python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5
```

#### å¤š GPU
ä½ å¯ä»¥ä½¿ç”¨æ¨¡å‹å¹¶è¡Œæ¥èšåˆåŒä¸€æœºå™¨ä¸Šå¤šä¸ª GPU çš„ GPU å†…å­˜ã€‚
```
python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5 --num-gpus 2
```

æç¤ºï¼š
æœ‰æ—¶ huggingface/transformers ä¸­çš„"auto"è®¾å¤‡æ˜ å°„ç­–ç•¥å¹¶ä¸èƒ½å®Œç¾å¹³è¡¡å¤šä¸ª GPU ä¹‹é—´çš„å†…å­˜åˆ†é…ã€‚
ä½ å¯ä»¥ä½¿ç”¨ `--max-gpu-memory` æ¥æŒ‡å®šæ¯ä¸ª GPU ç”¨äºå­˜å‚¨æ¨¡å‹æƒé‡çš„æœ€å¤§å†…å­˜ã€‚
è¿™å…è®¸å®ƒä¸ºæ¿€æ´»åˆ†é…æ›´å¤šå†…å­˜ï¼Œå› æ­¤ä½ å¯ä»¥ä½¿ç”¨æ›´é•¿çš„ä¸Šä¸‹æ–‡é•¿åº¦æˆ–æ›´å¤§çš„æ‰¹é‡å¤§å°ã€‚ä¾‹å¦‚ï¼š

```
python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5 --num-gpus 2 --max-gpu-memory 8GiB
```

#### ä»… CPU
è¿™ä»…åœ¨ CPU ä¸Šè¿è¡Œï¼Œä¸éœ€è¦ GPUã€‚å®ƒéœ€è¦çº¦ 30GB CPU å†…å­˜ç”¨äº Vicuna-7Bï¼Œçº¦ 60GB CPU å†…å­˜ç”¨äº Vicuna-13Bã€‚
```
python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5 --device cpu
```

ä½¿ç”¨ Intel AI åŠ é€Ÿå™¨ AVX512_BF16/AMX æ¥åŠ é€Ÿ CPU æ¨ç†ã€‚
```
CPU_ISA=amx python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5 --device cpu
```

#### Metal åç«¯ï¼ˆæ­è½½ Apple Silicon æˆ– AMD GPU çš„ Mac ç”µè„‘ï¼‰
ä½¿ç”¨ `--device mps` åœ¨ Mac ç”µè„‘ä¸Šå¯ç”¨ GPU åŠ é€Ÿï¼ˆéœ€è¦ torch >= 2.0ï¼‰ã€‚
ä½¿ç”¨ `--load-8bit` å¼€å¯ 8 ä½å‹ç¼©ã€‚
```
python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5 --device mps --load-8bit
```
Vicuna-7B å¯ä»¥åœ¨ 32GB M1 Macbook ä¸Šä»¥ 1-2 å­—/ç§’çš„é€Ÿåº¦è¿è¡Œã€‚

#### Intel XPUï¼ˆIntel æ•°æ®ä¸­å¿ƒå’Œ Arc A ç³»åˆ— GPUï¼‰
å®‰è£… [Intel Extension for PyTorch](https://intel.github.io/intel-extension-for-pytorch/xpu/latest/tutorials/installation.html)ã€‚è®¾ç½® OneAPI ç¯å¢ƒå˜é‡ï¼š
```
source /opt/intel/oneapi/setvars.sh
```

ä½¿ç”¨ `--device xpu` å¯ç”¨ XPU/GPU åŠ é€Ÿã€‚
```
python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5 --device xpu
```
Vicuna-7B å¯ä»¥åœ¨ Intel Arc A770 16GB ä¸Šè¿è¡Œã€‚

#### Ascend NPU
å®‰è£… [Ascend PyTorch Adapter](https://github.com/Ascend/pytorch)ã€‚è®¾ç½® CANN ç¯å¢ƒå˜é‡ï¼š
```
source /usr/local/Ascend/ascend-toolkit/set_env.sh
```

ä½¿ç”¨ `--device npu` å¯ç”¨ NPU åŠ é€Ÿã€‚
```
python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5 --device npu
```
Vicuna-7B/13B å¯ä»¥åœ¨ Ascend NPU ä¸Šè¿è¡Œã€‚

#### å†…å­˜ä¸è¶³
å¦‚æœä½ æ²¡æœ‰è¶³å¤Ÿçš„å†…å­˜ï¼Œå¯ä»¥é€šè¿‡åœ¨ä¸Šè¿°å‘½ä»¤ä¸­æ·»åŠ  `--load-8bit` æ¥å¯ç”¨ 8 ä½å‹ç¼©ã€‚
è¿™å¯ä»¥å°†å†…å­˜ä½¿ç”¨é‡å‡å°‘çº¦ä¸€åŠï¼Œæ¨¡å‹è´¨é‡ç•¥æœ‰ä¸‹é™ã€‚
å®ƒä¸ CPUã€GPU å’Œ Metal åç«¯å…¼å®¹ã€‚

ä½¿ç”¨ 8 ä½å‹ç¼©çš„ Vicuna-13B å¯ä»¥åœ¨å…·æœ‰ 16GB VRAM çš„å•ä¸ª GPU ä¸Šè¿è¡Œï¼Œå¦‚ Nvidia RTX 3090ã€RTX 4080ã€T4ã€V100ï¼ˆ16GBï¼‰æˆ– AMD RX 6800 XTã€‚

```
python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5 --load-8bit
```

é™¤æ­¤ä¹‹å¤–ï¼Œä½ å¯ä»¥åœ¨ä¸Šè¿°å‘½ä»¤ä¸­æ·»åŠ  `--cpu-offloading` å°†ä¸é€‚åˆ GPU çš„æƒé‡å¸è½½åˆ° CPU å†…å­˜ä¸­ã€‚
è¿™éœ€è¦å¯ç”¨ 8 ä½å‹ç¼©å¹¶å®‰è£… bitsandbytes åŒ…ï¼Œè¯¥åŒ…ä»…åœ¨ linux æ“ä½œç³»ç»Ÿä¸Šå¯ç”¨ã€‚

#### æ›´å¤šå¹³å°å’Œé‡åŒ–
- å¯¹äº AMD GPU ç”¨æˆ·ï¼Œè¯·åœ¨å®‰è£… FastChat ä¹‹å‰å®‰è£… ROCm å’Œ [PyTorch çš„ ROCm ç‰ˆæœ¬](https://pytorch.org/get-started/locally/)ã€‚å¦è¯·å‚è§æ­¤[å¸–å­](https://github.com/lm-sys/FastChat/issues/104#issuecomment-1613791563)ã€‚
- FastChat æ”¯æŒ ExLlama V2ã€‚å‚è§ [docs/exllama_v2.md](/docs/exllama_v2.md)ã€‚
- FastChat æ”¯æŒä½¿ç”¨ [GPTQ-for-LLaMa](https://github.com/qwopqwop200/GPTQ-for-LLaMa) è¿›è¡Œ GPTQ 4 ä½æ¨ç†ã€‚å‚è§ [docs/gptq.md](/docs/gptq.md)ã€‚
- FastChat æ”¯æŒä½¿ç”¨ [mit-han-lab/llm-awq](https://github.com/mit-han-lab/llm-awq) è¿›è¡Œ AWQ 4 ä½æ¨ç†ã€‚å‚è§ [docs/awq.md](/docs/awq.md)ã€‚
- [MLC LLM](https://mlc.ai/mlc-llm/)ï¼Œç”± [TVM Unity](https://github.com/apache/tvm/tree/unity) ç¼–è¯‘å™¨æ”¯æŒï¼Œé€šè¿‡ Vulkanã€Metalã€CUDA å’Œ WebGPU åœ¨æ‰‹æœºã€æ¶ˆè´¹çº§ GPU å’Œç½‘ç»œæµè§ˆå™¨ä¸ŠåŸç”Ÿéƒ¨ç½² Vicunaã€‚

#### ä½¿ç”¨æ¥è‡ª modelscope çš„æ¨¡å‹
å¯¹äºä¸­å›½ç”¨æˆ·ï¼Œä½ å¯ä»¥é€šè¿‡æŒ‡å®šä»¥ä¸‹ç¯å¢ƒå˜é‡æ¥ä½¿ç”¨æ¥è‡ª www.modelscope.cn çš„æ¨¡å‹ã€‚
```bash
export FASTCHAT_USE_MODELSCOPE=True
```

## Web GUI æœåŠ¡

<a href="https://chat.lmsys.org"><img src="assets/screenshot_gui.png" width="70%"></a>

è¦ä½¿ç”¨ web UI è¿›è¡ŒæœåŠ¡ï¼Œä½ éœ€è¦ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼šä¸ç”¨æˆ·äº¤äº’çš„ web æœåŠ¡å™¨ã€æ‰˜ç®¡ä¸€ä¸ªæˆ–å¤šä¸ªæ¨¡å‹çš„æ¨¡å‹å·¥ä½œå™¨ï¼Œä»¥åŠåè°ƒ web æœåŠ¡å™¨å’Œæ¨¡å‹å·¥ä½œå™¨çš„æ§åˆ¶å™¨ã€‚ä½ å¯ä»¥åœ¨[è¿™é‡Œ](docs/server_arch.md)äº†è§£æ›´å¤šå…³äºæ¶æ„çš„ä¿¡æ¯ã€‚

ä»¥ä¸‹æ˜¯åœ¨ç»ˆç«¯ä¸­è¦éµå¾ªçš„å‘½ä»¤ï¼š

#### å¯åŠ¨æ§åˆ¶å™¨
```bash
python3 -m fastchat.serve.controller
```

æ­¤æ§åˆ¶å™¨ç®¡ç†åˆ†å¸ƒå¼å·¥ä½œå™¨ã€‚

#### å¯åŠ¨æ¨¡å‹å·¥ä½œå™¨
```bash
python3 -m fastchat.serve.model_worker --model-path lmsys/vicuna-7b-v1.5
```
ç­‰å¾…è¿›ç¨‹å®ŒæˆåŠ è½½æ¨¡å‹ï¼Œç›´åˆ°çœ‹åˆ°"Uvicorn running on ..."ã€‚æ¨¡å‹å·¥ä½œå™¨å°†è‡ªå·±æ³¨å†Œåˆ°æ§åˆ¶å™¨ã€‚

è¦ç¡®ä¿ä½ çš„æ¨¡å‹å·¥ä½œå™¨æ­£ç¡®è¿æ¥åˆ°æ§åˆ¶å™¨ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å‘é€æµ‹è¯•æ¶ˆæ¯ï¼š
```bash
python3 -m fastchat.serve.test_message --model-name vicuna-7b-v1.5
```
ä½ å°†çœ‹åˆ°ä¸€ä¸ªç®€çŸ­çš„è¾“å‡ºã€‚

#### å¯åŠ¨ Gradio web æœåŠ¡å™¨
```bash
python3 -m fastchat.serve.gradio_web_server
```

è¿™æ˜¯ç”¨æˆ·å°†ä¸ä¹‹äº¤äº’çš„ç”¨æˆ·ç•Œé¢ã€‚

é€šè¿‡éµå¾ªè¿™äº›æ­¥éª¤ï¼Œä½ å°†èƒ½å¤Ÿä½¿ç”¨ web UI æœåŠ¡ä½ çš„æ¨¡å‹ã€‚ä½ ç°åœ¨å¯ä»¥æ‰“å¼€æµè§ˆå™¨å¹¶ä¸æ¨¡å‹èŠå¤©ã€‚
å¦‚æœæ¨¡å‹æ²¡æœ‰æ˜¾ç¤ºï¼Œè¯·å°è¯•é‡å¯ gradio web æœåŠ¡å™¨ã€‚

#### ï¼ˆå¯é€‰ï¼‰ï¼šé«˜çº§åŠŸèƒ½ã€å¯æ‰©å±•æ€§ã€ç¬¬ä¸‰æ–¹ UI
- ä½ å¯ä»¥å‘å•ä¸ªæ§åˆ¶å™¨æ³¨å†Œå¤šä¸ªæ¨¡å‹å·¥ä½œå™¨ï¼Œè¿™å¯ç”¨äºä»¥æ›´é«˜ååé‡æœåŠ¡å•ä¸ªæ¨¡å‹æˆ–åŒæ—¶æœåŠ¡å¤šä¸ªæ¨¡å‹ã€‚åœ¨è¿™æ ·åšæ—¶ï¼Œè¯·ä¸ºä¸åŒçš„æ¨¡å‹å·¥ä½œå™¨åˆ†é…ä¸åŒçš„ GPU å’Œç«¯å£ã€‚
```
# å·¥ä½œå™¨ 0
CUDA_VISIBLE_DEVICES=0 python3 -m fastchat.serve.model_worker --model-path lmsys/vicuna-7b-v1.5 --controller http://localhost:21001 --port 31000 --worker http://localhost:31000
# å·¥ä½œå™¨ 1
CUDA_VISIBLE_DEVICES=1 python3 -m fastchat.serve.model_worker --model-path lmsys/fastchat-t5-3b-v1.0 --controller http://localhost:21001 --port 31001 --worker http://localhost:31001
```
- ä½ è¿˜å¯ä»¥å¯åŠ¨å¤šæ ‡ç­¾é¡µ gradio æœåŠ¡å™¨ï¼Œå…¶ä¸­åŒ…æ‹¬ Chatbot Arena æ ‡ç­¾é¡µã€‚
```bash
python3 -m fastchat.serve.gradio_web_server_multi
```
- åŸºäº huggingface/transformers çš„é»˜è®¤æ¨¡å‹å·¥ä½œå™¨å…·æœ‰å¾ˆå¥½çš„å…¼å®¹æ€§ï¼Œä½†å¯èƒ½ä¼šå¾ˆæ…¢ã€‚å¦‚æœä½ æƒ³è¦é«˜ååé‡çš„æ‰¹å¤„ç†æœåŠ¡ï¼Œå¯ä»¥å°è¯• [vLLM é›†æˆ](docs/vllm_integration.md)ã€‚
- å¦‚æœä½ æƒ³åœ¨è‡ªå·±çš„ UI æˆ–ç¬¬ä¸‰æ–¹ UI ä¸Šæ‰˜ç®¡å®ƒï¼Œè¯·å‚è§[ç¬¬ä¸‰æ–¹ UI](docs/third_party_ui.md)ã€‚

## API
### å…¼å®¹ OpenAI çš„ RESTful API å’Œ SDK
FastChat ä¸ºå…¶æ”¯æŒçš„æ¨¡å‹æä¾›å…¼å®¹ OpenAI çš„ APIï¼Œå› æ­¤ä½ å¯ä»¥å°† FastChat ç”¨ä½œ OpenAI API çš„æœ¬åœ°æ›¿ä»£å“ã€‚
FastChat æœåŠ¡å™¨ä¸ [openai-python](https://github.com/openai/openai-python) åº“å’Œ cURL å‘½ä»¤éƒ½å…¼å®¹ã€‚
REST API å¯ä»¥åœ¨ Google Colab å…è´¹ç‰ˆä¸Šæ‰§è¡Œï¼Œå¦‚æˆ‘ä»¬ä»“åº“ä¸­çš„ [FastChat_API_GoogleColab.ipynb](https://github.com/lm-sys/FastChat/blob/main/playground/FastChat_API_GoogleColab.ipynb) ç¬”è®°æœ¬æ‰€ç¤ºã€‚
å‚è§ [docs/openai_api.md](docs/openai_api.md)ã€‚

### Hugging Face ç”Ÿæˆ API
å‚è§ [fastchat/serve/huggingface_api.py](fastchat/serve/huggingface_api.py)ã€‚

### LangChain é›†æˆ
å‚è§ [docs/langchain_integration](docs/langchain_integration.md)ã€‚

## è¯„ä¼°
æˆ‘ä»¬ä½¿ç”¨ MT-benchï¼Œä¸€ç»„å…·æœ‰æŒ‘æˆ˜æ€§çš„å¤šè½®å¼€æ”¾å¼é—®é¢˜æ¥è¯„ä¼°æ¨¡å‹ã€‚
ä¸ºäº†è‡ªåŠ¨åŒ–è¯„ä¼°è¿‡ç¨‹ï¼Œæˆ‘ä»¬æç¤ºåƒ GPT-4 è¿™æ ·çš„å¼ºå¤§ LLM å……å½“è¯„åˆ¤ï¼Œè¯„ä¼°æ¨¡å‹å“åº”çš„è´¨é‡ã€‚
å‚è§ [fastchat/llm_judge](fastchat/llm_judge) ä¸­è¿è¡Œ MT-bench çš„è¯´æ˜ã€‚

MT-bench æ˜¯è¯„ä¼°ä½ çš„æ¨¡å‹çš„æ–°æ¨èæ–¹å¼ã€‚å¦‚æœä½ ä»åœ¨å¯»æ‰¾ vicuna åšå®¢æ–‡ç« ä¸­ä½¿ç”¨çš„æ—§çš„ 80 ä¸ªé—®é¢˜ï¼Œè¯·è®¿é—® [vicuna-blog-eval](https://github.com/lm-sys/vicuna-blog-eval)ã€‚

## å¾®è°ƒ
### æ•°æ®

Vicuna æ˜¯é€šè¿‡ä½¿ç”¨ä» ShareGPT.com æ”¶é›†çš„çº¦ 125K ç”¨æˆ·å…±äº«å¯¹è¯ï¼Œä½¿ç”¨å…¬å…± API å¯¹ Llama åŸºç¡€æ¨¡å‹è¿›è¡Œå¾®è°ƒåˆ›å»ºçš„ã€‚ä¸ºç¡®ä¿æ•°æ®è´¨é‡ï¼Œæˆ‘ä»¬å°† HTML è½¬æ¢å› markdownï¼Œå¹¶è¿‡æ»¤æ‰ä¸€äº›ä¸é€‚å½“æˆ–ä½è´¨é‡çš„æ ·æœ¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†å†—é•¿çš„å¯¹è¯åˆ†æˆé€‚åˆæ¨¡å‹æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦çš„è¾ƒå°æ®µè½ã€‚æœ‰å…³æ¸…ç† ShareGPT æ•°æ®çš„è¯¦ç»†è¯´æ˜ï¼Œè¯·æŸ¥çœ‹[è¿™é‡Œ](docs/commands/data_cleaning.md)ã€‚

æˆ‘ä»¬ä¸ä¼šå‘å¸ƒ ShareGPT æ•°æ®é›†ã€‚å¦‚æœä½ æƒ³å°è¯•å¾®è°ƒä»£ç ï¼Œä½ å¯ä»¥ä½¿ç”¨ [dummy_conversation.json](data/dummy_conversation.json) ä¸­çš„ä¸€äº›è™šæ‹Ÿå¯¹è¯è¿è¡Œå®ƒã€‚ä½ å¯ä»¥éµå¾ªç›¸åŒçš„æ ¼å¼å¹¶æ’å…¥ä½ è‡ªå·±çš„æ•°æ®ã€‚

### ä»£ç å’Œè¶…å‚æ•°
æˆ‘ä»¬çš„ä»£ç åŸºäº [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)ï¼Œå¹¶å¢åŠ äº†å¯¹å¤šè½®å¯¹è¯çš„æ”¯æŒã€‚
æˆ‘ä»¬ä½¿ç”¨ä¸ Stanford Alpaca ç±»ä¼¼çš„è¶…å‚æ•°ã€‚

| è¶…å‚æ•° | å…¨å±€æ‰¹é‡å¤§å° | å­¦ä¹ ç‡ | è½®æ•° | æœ€å¤§é•¿åº¦ | æƒé‡è¡°å‡ |
| --- | ---: | ---: | ---: | ---: | ---: |
| Vicuna-13B | 128 | 2e-5 | 3 | 2048 | 0 |

### ä½¿ç”¨æœ¬åœ° GPU å¾®è°ƒ Vicuna-7B

- å®‰è£…ä¾èµ–
```bash
pip3 install -e ".[train]"
```

- ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä½¿ç”¨ 4 x A100ï¼ˆ40GBï¼‰è®­ç»ƒ Vicuna-7Bã€‚ç”¨å®é™…çš„ Llama æƒé‡è·¯å¾„æ›´æ–° `--model_name_or_path`ï¼Œç”¨å®é™…çš„æ•°æ®è·¯å¾„æ›´æ–° `--data_path`ã€‚
```bash
torchrun --nproc_per_node=4 --master_port=20001 fastchat/train/train_mem.py \
    --model_name_or_path meta-llama/Llama-2-7b-hf \
    --data_path data/dummy_conversation.json \
    --bf16 True \
    --output_dir output_vicuna \
    --num_train_epochs 3 \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 16 \
    --evaluation_strategy "no" \
    --save_strategy "steps" \
    --save_steps 1200 \
    --save_total_limit 10 \
    --learning_rate 2e-5 \
    --weight_decay 0. \
    --warmup_ratio 0.03 \
    --lr_scheduler_type "cosine" \
    --logging_steps 1 \
    --fsdp "full_shard auto_wrap" \
    --fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \
    --tf32 True \
    --model_max_length 2048 \
    --gradient_checkpointing True \
    --lazy_preprocess True
```

æç¤ºï¼š
- å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ä¸æ”¯æŒ FlashAttention çš„ V100ï¼Œä½ å¯ä»¥ä½¿ç”¨ [xFormers](https://github.com/facebookresearch/xformers) ä¸­å®ç°çš„[å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›](https://arxiv.org/abs/2112.05682)ã€‚å®‰è£… xformers å¹¶å°†ä¸Šé¢çš„ `fastchat/train/train_mem.py` æ›¿æ¢ä¸º [fastchat/train/train_xformers.py](fastchat/train/train_xformers.py)ã€‚
- å¦‚æœä½ ç”±äº"FSDP Warning: When using FSDP, it is efficient and recommended..."è€Œé‡åˆ°å†…å­˜ä¸è¶³ï¼Œè¯·å‚è§[è¿™é‡Œ](https://github.com/huggingface/transformers/issues/24724#issuecomment-1645189539)çš„è§£å†³æ–¹æ¡ˆã€‚
- å¦‚æœä½ åœ¨æ¨¡å‹ä¿å­˜æœŸé—´é‡åˆ°å†…å­˜ä¸è¶³ï¼Œè¯·å‚è§[è¿™é‡Œ](https://github.com/pytorch/pytorch/issues/98823)çš„è§£å†³æ–¹æ¡ˆã€‚
- è¦å¼€å¯è®°å½•åˆ°æµè¡Œçš„å®éªŒè·Ÿè¸ªå·¥å…·ï¼ˆå¦‚ Tensorboardã€MLFlow æˆ– Weights & Biasesï¼‰ï¼Œè¯·ä½¿ç”¨ `report_to` å‚æ•°ï¼Œä¾‹å¦‚ä¼ é€’ `--report_to wandb` ä»¥å¼€å¯è®°å½•åˆ° Weights & Biasesã€‚

### å…¶ä»–æ¨¡å‹ã€å¹³å°å’Œ LoRA æ”¯æŒ
æ›´å¤šå…³äºè®­ç»ƒå…¶ä»–æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼ŒFastChat-T5ï¼‰å’Œä½¿ç”¨ LoRA çš„è¯´æ˜åœ¨ [docs/training.md](docs/training.md) ä¸­ã€‚

### ä½¿ç”¨ SkyPilot åœ¨ä»»ä½•äº‘ä¸Šå¾®è°ƒ
[SkyPilot](https://github.com/skypilot-org/skypilot) æ˜¯ç”±åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡å¼€å‘çš„æ¡†æ¶ï¼Œç”¨äºåœ¨ä»»ä½•äº‘ï¼ˆAWSã€GCPã€Azureã€Lambda ç­‰ï¼‰ä¸Šè½»æ¾ä¸”ç»æµé«˜æ•ˆåœ°è¿è¡Œ ML å·¥ä½œè´Ÿè½½ã€‚
åœ¨[è¿™é‡Œ](https://github.com/skypilot-org/skypilot/tree/master/llm/vicuna)æŸ¥çœ‹ SkyPilot æ–‡æ¡£ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨æ‰˜ç®¡ç«ä»·å®ä¾‹æ¥è®­ç»ƒ Vicuna å¹¶èŠ‚çœäº‘æˆæœ¬ã€‚

## å¼•ç”¨
æœ¬ä»“åº“ä¸­çš„ä»£ç ï¼ˆè®­ç»ƒã€æœåŠ¡å’Œè¯„ä¼°ï¼‰ä¸»è¦æ˜¯ä¸ºä»¥ä¸‹è®ºæ–‡å¼€å‘æˆ–ä»ä¸­æ´¾ç”Ÿçš„ã€‚
å¦‚æœä½ è§‰å¾—è¯¥ä»“åº“æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨å®ƒã€‚

```
@misc{zheng2023judging,
      title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

æˆ‘ä»¬ä¹Ÿè®¡åˆ’å‘è¿™ä¸ªä»“åº“æ·»åŠ æ›´å¤šæˆ‘ä»¬çš„ç ”ç©¶ã€‚
